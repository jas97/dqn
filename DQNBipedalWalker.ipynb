{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import glob\n",
    "import io\n",
    "import gym\n",
    "import numpy as np\n",
    "from gym import wrappers\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "from IPython.display import Video\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local imports\n",
    "from helper import show_video, get_env, play_random_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup environment\n",
    "env = get_env('BipedalWalker-v2')\n",
    "env = wrappers.Monitor(env, 'video/', force=True)\n",
    "observation = env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of steps: 1600\n",
      "Total reward: -72.41695747063982\n",
      "['video\\\\openaigym.video.1.7556.video000000.mp4']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                                    <video alt=\"test\" controls>\n",
       "                                        <source src=\"video\\openaigym.video.1.7556.video000000.mp4\" type=\"video/mp4\">\n",
       "                                    </video>\n",
       "                                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# play random episode\n",
    "play_random_episode(env)\n",
    "show_video('video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment params\n",
    "NUM_ACTIONS = env.action_space.shape[0]\n",
    "NUM_FEATURES = env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model params\n",
    "HIDDEN_DIM = 32\n",
    "MAX_BUFFER_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(NUM_FEATURES, HIDDEN_DIM)\n",
    "        self.fc2 = nn.Linear(HIDDEN_DIM, HIDDEN_DIM)\n",
    "        self.output = nn.Linear(HIDDEN_DIM, NUM_ACTIONS)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = DQN()\n",
    "        self.target_model = DQN()\n",
    "        \n",
    "        self.replay_buffer = deque()\n",
    "        \n",
    "    def fill_buffer(self):\n",
    "        pass\n",
    "    \n",
    "    def sample_buffer(self, batch_size):\n",
    "        pass\n",
    "    \n",
    "    def train(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dqn agent\n",
    "dqn_agent = DQNAgent()\n",
    "dqn_agent.fill_buffer()\n",
    "dqn_agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play episode with trained agent\n",
    "done = False\n",
    "cnt = 0\n",
    "total_reward = 0\n",
    "while not done:\n",
    "    cnt += 1\n",
    "    action = dqn_agent(observation)\n",
    "    observation, reward, done, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    if done:\n",
    "        break\n",
    "print(\"number of steps: {}\".format(cnt))\n",
    "print('Total reward: {}'.format(total_reward))\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
